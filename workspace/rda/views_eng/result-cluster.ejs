<main class="search__main">
    <div class="top_border"></div>
    <div class="side_menu">
        <ul id="explain_ul">
            <li><a href="/results/classification"><img src="/images/classification.png" id="menu_icon"></a></li>
            <li>Classification</li>
        </ul>
        <ul id="explain_ul">
            <li><a href="/results/feature"><img src="/images/feature-selection.png" id="menu_icon"></a></li>
            <li>Feature Selection</li>
        </ul>
        <ul id="explain_ul">
            <li><a href="/results/corr"><img src="/images/matrix2.png" id="menu_icon"></a></li>
            <li>Correlation Analysis</li>
        </ul>
    </div>
    <div class="search__result">
        <!--explain classification-->
        <div class="explain_div">
            <ul id="explain_ul">
                <li><a href="/results/cluster"><img src="/images/cluster.png" id="menu_icon"></a></li>
                <li style="font-weight: 700;">Clustering</li>
            </ul>
            <div id="explain_content">
                <h1>What is Clustering? :</h1> <br>
                Clustering is an unsupervised machine learning task.
                It involves automatically discovering natural grouping in data.
                Unlike supervised learning (like predictive modeling), clustering algorithms only interpret the input
                data and find natural groups or clusters in feature space. <br>
                <p style="font-weight: 200;">
                    <br>
                    (Unsupervised learning (UL) is a type of algorithm that learns patterns from untagged data. The hope
                    is that through mimicry, the machine is forced to build a compact internal representation of its
                    world.)

                    <br><br>
                <details>
                    <summary>Algorithms</summary>
                    <p>
                        <br>
                        ∙ K-means Clustering : <br>
                        K-means clustering is a type of unsupervised learning. The goal of this algorithm is to find
                        groups in the data, with the number of groups represented by the variable K. The algorithm works
                        iteratively to assign each data point to one of K groups based on the features that are
                        provided. Data points are clustered based on feature similarity.<br><br>
                        ∙ DBSCAN : <br>
                        Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a base algorithm for
                        density-based clustering. It can discover clusters of different shapes and sizes from a large
                        amount of data, which is containing noise and outliers.<br><br>
                        ∙ Hierarchial Clustering : <br>
                        Linear Regression is a supervised machine learning algorithm where the predicted output is
                        continuous and has a constant slope. It's used to predict values within a continuous range,
                        (e.g. sales, price) rather than trying to classify them into categories (e.g. cat, dog). There
                        are two main types: Simple regression and Multivariable regression.

                    </p>
                </details>

                </p>

            </div>
        </div>
        <!--set parameters & results-->
        <div class="main_div">
            <div class="parameters">
                <h2>Choose Parameters</h2>
                <!--run and post to fileProcess.js's /classification-run-->
                <form action="/file/clustering-run" method="POST" class="param-form">
                    <div>
                        <h3>K-means Clustering</h3>
                        ∙ n_clusters
                        <p style="font-size: x-small;">
                            The number of clusters to form as well as the number of centroids to generate.
                            <br> <br>(int, default=8)
                        </p>
                        <input type="text" name="kmeans_n_clusters" value="<%=param_cluster.kmeans_n_clusters%>">
                        <br>
                        ∙ max_iter
                        <p style="font-size: x-small;">
                            Maximum number of iterations of the k-means algorithm for a single run.
                            <br> <br>(int, default=300)
                        </p>
                        <input type="text" name="max_iter" value="<%=param_cluster.max_iter%>">



                    </div>
                    <div>
                        <h3>DBSCAN</h3>
                        ∙ eps
                        <p style="font-size: x-small;">
                            The maximum distance between two samples for one to be considered as in the neighborhood of
                            the other. This is not a maximum bound on the distances of points within a cluster. This is
                            the most important DBSCAN parameter to choose appropriately for your data set and distance
                            function.
                            <br><br>(float, default=0.5)
                        </p>

                        <input type="text" name="eps" value="<%=param_cluster.eps%>">
                        <br>
                        ∙ min_samples
                        <p style="font-size: x-small;">
                            The number of samples (or total weight) in a neighborhood for a point to be considered as a
                            core point. This includes the point itself.
                            <br><br>(int, default=5)
                        </p>

                        <input type="text" name="min_samples" value="<%=param_cluster.min_samples%>">

                    </div>
                    <div>
                        <h3>Hierarchial Clustering</h3>
                        ∙ n_clusters
                        <p style="font-size: x-small;">
                            The number of clusters to find. It must be None if distance_threshold is not None.
                            <br><br>(int or None, default=2)
                        </p>

                        <input type="text" name="hc_n_clusters" value="<%=param_cluster.hc_n_clusters%>">

                    </div>
                    <div id="loading" style="display: block;z-index: 99;">
                        <img src="/images/loading.gif" style=" position: absolute;margin-left:18%;z-index: 100;">
                    </div>
                    <div class="btn-wrapper">
                        <input type="submit" id="btn" value="Run"></input>

                    </div>


                </form>
            </div>
            <div class="result_div">
                <h2>Results</h2>
                <div class="result_content">

                    <div class="result-image-wrapper2">
                        <h3>Silhouette Score</h3>
                        <p>Kmeans clustering was used to check Silhouette score. In general, if the silhouette score of
                            all clusters is greater than 0.5, it seems that data is well clustered. </p>
                        <p style="font-weight: 200;font-size: x-small;"> <br> ▪ Click on an image for more details.</p>
                        <img src="/files/<%=maindata.cluster_img1%>" class="result-image" />
                        <h3>Dendrogram</h3>
                        <p>The complete linkage method was used to measure the distance between clusters, which is the
                            method that uses the farthest distance between the two clusters.</p>
                        <p style="font-weight: 200;font-size: x-small;">▪ Click on an image for more details.</p>
                        <img src="/files/<%=maindata.cluster_img2%>" class="result-image" />
                        <h3>PCA</h3>
                        <p>After reducing the dimension to 2D with 2D principal component analysis(2 component PCA),
                            K-means clustering was performed on 4 clusters.</p>
                        <details>
                            <summary>What is PCA(Principal Component Analysis)? </summary>
                            <p>
                                Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often
                                used to reduce the dimensionality of large data sets, by transforming a large set of
                                variables into a smaller one that still contains most of the information in the large
                                set. Reducing the number of variables of a data set naturally comes at the expense of
                                accuracy, but the trick in dimensionality reduction is to trade a little accuracy for
                                simplicity. Because smaller data sets are easier to explore and visualize and make
                                analyzing data much easier and faster for machine learning algorithms without extraneous
                                variables to process. In conclusion, the idea of PCA is that reduce the number of
                                variables of a data set, while preserving as much information as possible.

                            </p>
                        </details>
                        <p style="font-weight: 200;font-size: x-small;"> <br> ▪ Click on an image for more details.</p>
                        <img src="/files/<%=maindata.pca_img%>" class="result-image" />

                    </div>

                </div>

                <div class="file-download">
                    <% if(Object.keys(maindata).length !=0) { %>
                        <button type="button" id="res_btn" data-tooltip-text="<%=maindata.cluster_img1%>
                                <%=maindata.cluster_img2%>
                                <%=maindata.pca_img%>
                                <%=maindata.resultfilename4%>
				<%=maindata.resultfilename5%>
				<%=maindata.resultfilename8%>">
                            <a href="/file/clustering_<%=maindata.filename%>_.zip">Result File Download</a></button>

                        <% } %>
                </div>
            </div>
        </div>
    </div>
    </div>


</main>
<script>
    document.getElementById("loading").style.display = "none";
    let submitBtn = document.querySelector(".param-form #btn");
    submitBtn.addEventListener("click", function (event) {
        document.getElementById("loading").style.display = "block";
    });


</script>

<script type="text/javascript">
    var img = document.getElementsByClassName('result-image');
    for (var x = 0; x < img.length; x++) {
        img.item(x).onclick = function () { window.open(this.src) };
    }
</script>